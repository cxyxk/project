{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cxyxk/project/blob/master/xk_com.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzlKF44oFq2o",
        "outputId": "d5c149de-3c34-4cea-9fb2-a356b1143395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-OFDGhw92MG",
        "outputId": "5e549022-2de1-45c4-c215-918fc98bcdbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn tensorflow requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8yXvuBRGqz6",
        "outputId": "dbb2f95e-f30d-4c6e-9b64-30279afc750e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr2DtHUM95G3",
        "outputId": "279d9104-65c7-4fea-b3bb-87a168f08aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 466ms/step - accuracy: 0.0076 - loss: 5.4067 - val_accuracy: 0.0000e+00 - val_loss: 4.6989 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.2271 - loss: 3.9432 - val_accuracy: 0.0000e+00 - val_loss: 4.6779 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.1803 - loss: 3.6793 - val_accuracy: 0.0000e+00 - val_loss: 4.6621 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.2157 - loss: 3.4955 - val_accuracy: 0.0000e+00 - val_loss: 4.6511 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.3067 - loss: 3.2220 - val_accuracy: 0.0000e+00 - val_loss: 4.6416 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - accuracy: 0.3039 - loss: 3.0678 - val_accuracy: 0.0000e+00 - val_loss: 4.6315 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.3165 - loss: 3.0290 - val_accuracy: 0.0000e+00 - val_loss: 4.6207 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 261ms/step - accuracy: 0.3553 - loss: 2.7680 - val_accuracy: 0.0000e+00 - val_loss: 4.6090 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.3886 - loss: 2.7283 - val_accuracy: 0.0000e+00 - val_loss: 4.5974 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.4138 - loss: 2.6351 - val_accuracy: 0.0000e+00 - val_loss: 4.5868 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.4159 - loss: 2.5234 - val_accuracy: 0.0000e+00 - val_loss: 4.5775 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.3968 - loss: 2.5278 - val_accuracy: 0.0000e+00 - val_loss: 4.5732 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step - accuracy: 0.3768 - loss: 2.4713 - val_accuracy: 0.0000e+00 - val_loss: 4.5691 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step - accuracy: 0.4331 - loss: 2.4331 - val_accuracy: 0.0000e+00 - val_loss: 4.5660 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.4457 - loss: 2.3065 - val_accuracy: 0.0000e+00 - val_loss: 4.5649 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.4394 - loss: 2.3354 - val_accuracy: 0.0000e+00 - val_loss: 4.5650 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.4831 - loss: 2.1454 - val_accuracy: 0.0000e+00 - val_loss: 4.5630 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.4899 - loss: 2.1273 - val_accuracy: 0.0000e+00 - val_loss: 4.5638 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.4818 - loss: 2.1496 - val_accuracy: 0.0000e+00 - val_loss: 4.5645 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.4859 - loss: 2.0884 - val_accuracy: 0.0000e+00 - val_loss: 4.5617 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.4979 - loss: 2.0843 - val_accuracy: 0.0000e+00 - val_loss: 4.5597 - learning_rate: 0.0010\n",
            "Epoch 22/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.5249 - loss: 1.9411 - val_accuracy: 0.0000e+00 - val_loss: 4.5577 - learning_rate: 0.0010\n",
            "Epoch 23/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.5418 - loss: 1.9254 - val_accuracy: 0.0000e+00 - val_loss: 4.5555 - learning_rate: 0.0010\n",
            "Epoch 24/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - accuracy: 0.5230 - loss: 2.1080 - val_accuracy: 0.0000e+00 - val_loss: 4.5495 - learning_rate: 0.0010\n",
            "Epoch 25/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.4926 - loss: 2.0185 - val_accuracy: 0.0000e+00 - val_loss: 4.5438 - learning_rate: 0.0010\n",
            "Epoch 26/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - accuracy: 0.5001 - loss: 2.0562 - val_accuracy: 0.0000e+00 - val_loss: 4.5423 - learning_rate: 0.0010\n",
            "Epoch 27/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.5841 - loss: 1.8906 - val_accuracy: 0.0000e+00 - val_loss: 4.5409 - learning_rate: 0.0010\n",
            "Epoch 28/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255ms/step - accuracy: 0.5064 - loss: 2.0189 - val_accuracy: 0.0000e+00 - val_loss: 4.5408 - learning_rate: 0.0010\n",
            "Epoch 29/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.6032 - loss: 1.8612 - val_accuracy: 0.0000e+00 - val_loss: 4.5421 - learning_rate: 0.0010\n",
            "Epoch 30/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.6012 - loss: 1.7974 - val_accuracy: 0.0000e+00 - val_loss: 4.5417 - learning_rate: 0.0010\n",
            "Epoch 31/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.5911 - loss: 1.8596 - val_accuracy: 0.0000e+00 - val_loss: 4.5299 - learning_rate: 0.0010\n",
            "Epoch 32/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.5929 - loss: 1.8457 - val_accuracy: 0.0000e+00 - val_loss: 4.5175 - learning_rate: 0.0010\n",
            "Epoch 33/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.5937 - loss: 1.7866 - val_accuracy: 0.0000e+00 - val_loss: 4.5116 - learning_rate: 0.0010\n",
            "Epoch 34/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.6073 - loss: 1.7093 - val_accuracy: 0.0000e+00 - val_loss: 4.5082 - learning_rate: 0.0010\n",
            "Epoch 35/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.6195 - loss: 1.7505 - val_accuracy: 0.0200 - val_loss: 4.4993 - learning_rate: 0.0010\n",
            "Epoch 36/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 426ms/step - accuracy: 0.6636 - loss: 1.7973 - val_accuracy: 0.0000e+00 - val_loss: 4.4999 - learning_rate: 0.0010\n",
            "Epoch 37/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 283ms/step - accuracy: 0.6705 - loss: 1.6699 - val_accuracy: 0.0000e+00 - val_loss: 4.5042 - learning_rate: 0.0010\n",
            "Epoch 38/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.5968 - loss: 1.7638 - val_accuracy: 0.0000e+00 - val_loss: 4.5081 - learning_rate: 0.0010\n",
            "Epoch 39/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.6449 - loss: 1.6457 - val_accuracy: 0.0000e+00 - val_loss: 4.5095 - learning_rate: 0.0010\n",
            "Epoch 40/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.5913 - loss: 1.6766 - val_accuracy: 0.0000e+00 - val_loss: 4.5088 - learning_rate: 0.0010\n",
            "Epoch 41/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.6630 - loss: 1.5492 - val_accuracy: 0.0000e+00 - val_loss: 4.5095 - learning_rate: 0.0010\n",
            "Epoch 42/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.6251 - loss: 1.6075 - val_accuracy: 0.0000e+00 - val_loss: 4.5160 - learning_rate: 0.0010\n",
            "Epoch 43/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.5849 - loss: 1.8111 - val_accuracy: 0.0000e+00 - val_loss: 4.5224 - learning_rate: 0.0010\n",
            "Epoch 44/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.6584 - loss: 1.5499 - val_accuracy: 0.0000e+00 - val_loss: 4.5227 - learning_rate: 0.0010\n",
            "Epoch 45/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.7011 - loss: 1.5472 - val_accuracy: 0.0000e+00 - val_loss: 4.5196 - learning_rate: 0.0010\n",
            "Epoch 46/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 0.6761 - loss: 1.4551 - val_accuracy: 0.0000e+00 - val_loss: 4.5081 - learning_rate: 0.0010\n",
            "Epoch 47/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 0.7186 - loss: 1.4729 - val_accuracy: 0.0000e+00 - val_loss: 4.4941 - learning_rate: 0.0010\n",
            "Epoch 48/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7259 - loss: 1.4440 - val_accuracy: 0.0200 - val_loss: 4.4763 - learning_rate: 0.0010\n",
            "Epoch 49/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.6911 - loss: 1.4676 - val_accuracy: 0.0400 - val_loss: 4.4657 - learning_rate: 0.0010\n",
            "Epoch 50/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.6890 - loss: 1.4581 - val_accuracy: 0.0600 - val_loss: 4.4677 - learning_rate: 0.0010\n",
            "Epoch 51/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 0.6664 - loss: 1.4882 - val_accuracy: 0.0600 - val_loss: 4.4732 - learning_rate: 0.0010\n",
            "Epoch 52/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 0.6744 - loss: 1.5319 - val_accuracy: 0.0600 - val_loss: 4.4748 - learning_rate: 1.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.7257 - loss: 1.4410 - val_accuracy: 0.0400 - val_loss: 4.4765 - learning_rate: 1.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.7087 - loss: 1.4100 - val_accuracy: 0.0400 - val_loss: 4.4792 - learning_rate: 1.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.7029 - loss: 1.4109 - val_accuracy: 0.0400 - val_loss: 4.4824 - learning_rate: 1.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - accuracy: 0.7126 - loss: 1.3977 - val_accuracy: 0.0400 - val_loss: 4.4839 - learning_rate: 1.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - accuracy: 0.7398 - loss: 1.3657 - val_accuracy: 0.0400 - val_loss: 4.4841 - learning_rate: 1.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.7501 - loss: 1.3973 - val_accuracy: 0.0400 - val_loss: 4.4851 - learning_rate: 1.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7126 - loss: 1.3430 - val_accuracy: 0.0400 - val_loss: 4.4849 - learning_rate: 1.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 0.7089 - loss: 1.4502 - val_accuracy: 0.0400 - val_loss: 4.4871 - learning_rate: 1.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7188 - loss: 1.3758 - val_accuracy: 0.0200 - val_loss: 4.4898 - learning_rate: 1.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7726 - loss: 1.3277 - val_accuracy: 0.0200 - val_loss: 4.4915 - learning_rate: 1.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.7306 - loss: 1.3998 - val_accuracy: 0.0400 - val_loss: 4.4930 - learning_rate: 1.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7544 - loss: 1.3099 - val_accuracy: 0.0400 - val_loss: 4.4947 - learning_rate: 1.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 0.7588 - loss: 1.3342 - val_accuracy: 0.0400 - val_loss: 4.4957 - learning_rate: 1.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7173 - loss: 1.3297 - val_accuracy: 0.0400 - val_loss: 4.4979 - learning_rate: 1.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - accuracy: 0.7257 - loss: 1.3884 - val_accuracy: 0.0400 - val_loss: 4.4992 - learning_rate: 1.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - accuracy: 0.7393 - loss: 1.4207 - val_accuracy: 0.0400 - val_loss: 4.5007 - learning_rate: 1.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.7510 - loss: 1.2983 - val_accuracy: 0.0400 - val_loss: 4.5025 - learning_rate: 1.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.8620 - loss: 1.2069 - val_accuracy: 0.0400 - val_loss: 4.5042 - learning_rate: 1.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7640 - loss: 1.2817 - val_accuracy: 0.0400 - val_loss: 4.5066 - learning_rate: 1.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.7875 - loss: 1.2549 - val_accuracy: 0.0400 - val_loss: 4.5100 - learning_rate: 1.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7655 - loss: 1.2753 - val_accuracy: 0.0400 - val_loss: 4.5128 - learning_rate: 1.0000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7834 - loss: 1.2821 - val_accuracy: 0.0400 - val_loss: 4.5154 - learning_rate: 1.0000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7952 - loss: 1.2534 - val_accuracy: 0.0400 - val_loss: 4.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - accuracy: 0.8103 - loss: 1.2569 - val_accuracy: 0.0400 - val_loss: 4.5225 - learning_rate: 1.0000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 0.7411 - loss: 1.2852 - val_accuracy: 0.0400 - val_loss: 4.5251 - learning_rate: 1.0000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - accuracy: 0.7717 - loss: 1.2750 - val_accuracy: 0.0400 - val_loss: 4.5294 - learning_rate: 1.0000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.7496 - loss: 1.3001 - val_accuracy: 0.0200 - val_loss: 4.5338 - learning_rate: 1.0000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7645 - loss: 1.2260 - val_accuracy: 0.0200 - val_loss: 4.5391 - learning_rate: 1.0000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step - accuracy: 0.8237 - loss: 1.2312 - val_accuracy: 0.0400 - val_loss: 4.5446 - learning_rate: 1.0000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7505 - loss: 1.2647 - val_accuracy: 0.0400 - val_loss: 4.5490 - learning_rate: 1.0000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - accuracy: 0.7140 - loss: 1.3177 - val_accuracy: 0.0400 - val_loss: 4.5517 - learning_rate: 1.0000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7916 - loss: 1.2459 - val_accuracy: 0.0400 - val_loss: 4.5538 - learning_rate: 1.0000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - accuracy: 0.7755 - loss: 1.2504 - val_accuracy: 0.0200 - val_loss: 4.5555 - learning_rate: 1.0000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399ms/step - accuracy: 0.7801 - loss: 1.2673 - val_accuracy: 0.0200 - val_loss: 4.5596 - learning_rate: 1.0000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.7707 - loss: 1.2382 - val_accuracy: 0.0200 - val_loss: 4.5621 - learning_rate: 1.0000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7590 - loss: 1.2517 - val_accuracy: 0.0200 - val_loss: 4.5683 - learning_rate: 1.0000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7519 - loss: 1.2274 - val_accuracy: 0.0200 - val_loss: 4.5759 - learning_rate: 1.0000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7756 - loss: 1.2078 - val_accuracy: 0.0200 - val_loss: 4.5840 - learning_rate: 1.0000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step - accuracy: 0.7262 - loss: 1.3494 - val_accuracy: 0.0200 - val_loss: 4.5921 - learning_rate: 1.0000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.8109 - loss: 1.1862 - val_accuracy: 0.0200 - val_loss: 4.5982 - learning_rate: 1.0000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7129 - loss: 1.3180 - val_accuracy: 0.0200 - val_loss: 4.6057 - learning_rate: 1.0000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.8300 - loss: 1.1777 - val_accuracy: 0.0200 - val_loss: 4.6137 - learning_rate: 1.0000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.7905 - loss: 1.2252 - val_accuracy: 0.0200 - val_loss: 4.6206 - learning_rate: 1.0000e-04\n",
            "Epoch 96/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 274ms/step - accuracy: 0.8366 - loss: 1.1692 - val_accuracy: 0.0200 - val_loss: 4.6285 - learning_rate: 1.0000e-04\n",
            "Epoch 97/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 266ms/step - accuracy: 0.7767 - loss: 1.2662 - val_accuracy: 0.0200 - val_loss: 4.6351 - learning_rate: 1.0000e-04\n",
            "Epoch 98/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 0.8238 - loss: 1.1675 - val_accuracy: 0.0200 - val_loss: 4.6440 - learning_rate: 1.0000e-04\n",
            "Epoch 99/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7807 - loss: 1.2691 - val_accuracy: 0.0200 - val_loss: 4.6494 - learning_rate: 1.0000e-04\n",
            "Epoch 100/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.8373 - loss: 1.1597 - val_accuracy: 0.0200 - val_loss: 4.6570 - learning_rate: 1.0000e-04\n",
            "Epoch 101/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.8390 - loss: 1.1728 - val_accuracy: 0.0200 - val_loss: 4.6675 - learning_rate: 1.0000e-04\n",
            "Epoch 102/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.8378 - loss: 1.1615 - val_accuracy: 0.0200 - val_loss: 4.6779 - learning_rate: 1.0000e-06\n",
            "Epoch 103/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - accuracy: 0.7832 - loss: 1.2312 - val_accuracy: 0.0200 - val_loss: 4.6863 - learning_rate: 1.0000e-06\n",
            "Epoch 104/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.7735 - loss: 1.2673 - val_accuracy: 0.0200 - val_loss: 4.6950 - learning_rate: 1.0000e-06\n",
            "Epoch 105/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256ms/step - accuracy: 0.7802 - loss: 1.2058 - val_accuracy: 0.0200 - val_loss: 4.7038 - learning_rate: 1.0000e-06\n",
            "Epoch 106/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7798 - loss: 1.1411 - val_accuracy: 0.0200 - val_loss: 4.7131 - learning_rate: 1.0000e-06\n",
            "Epoch 107/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7860 - loss: 1.2702 - val_accuracy: 0.0200 - val_loss: 4.7222 - learning_rate: 1.0000e-06\n",
            "Epoch 108/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7815 - loss: 1.2188 - val_accuracy: 0.0200 - val_loss: 4.7327 - learning_rate: 1.0000e-06\n",
            "Epoch 109/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.8686 - loss: 1.1161 - val_accuracy: 0.0200 - val_loss: 4.7402 - learning_rate: 1.0000e-06\n",
            "Epoch 110/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.8052 - loss: 1.2040 - val_accuracy: 0.0200 - val_loss: 4.7487 - learning_rate: 1.0000e-06\n",
            "Epoch 111/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7894 - loss: 1.2070 - val_accuracy: 0.0200 - val_loss: 4.7584 - learning_rate: 1.0000e-06\n",
            "Epoch 112/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7743 - loss: 1.2352 - val_accuracy: 0.0200 - val_loss: 4.7680 - learning_rate: 1.0000e-06\n",
            "Epoch 113/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - accuracy: 0.7671 - loss: 1.2419 - val_accuracy: 0.0200 - val_loss: 4.7783 - learning_rate: 1.0000e-06\n",
            "Epoch 114/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7699 - loss: 1.2347 - val_accuracy: 0.0200 - val_loss: 4.7884 - learning_rate: 1.0000e-06\n",
            "Epoch 115/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.7959 - loss: 1.1722 - val_accuracy: 0.0200 - val_loss: 4.7974 - learning_rate: 1.0000e-06\n",
            "Epoch 116/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.8211 - loss: 1.1750 - val_accuracy: 0.0200 - val_loss: 4.8064 - learning_rate: 1.0000e-06\n",
            "Epoch 117/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7665 - loss: 1.2584 - val_accuracy: 0.0200 - val_loss: 4.8177 - learning_rate: 1.0000e-06\n",
            "Epoch 118/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7990 - loss: 1.2571 - val_accuracy: 0.0200 - val_loss: 4.8285 - learning_rate: 1.0000e-06\n",
            "Epoch 119/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.7997 - loss: 1.1992 - val_accuracy: 0.0200 - val_loss: 4.8393 - learning_rate: 1.0000e-06\n",
            "Epoch 120/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.7611 - loss: 1.2389 - val_accuracy: 0.0200 - val_loss: 4.8498 - learning_rate: 1.0000e-06\n",
            "Epoch 121/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.7946 - loss: 1.1886 - val_accuracy: 0.0200 - val_loss: 4.8614 - learning_rate: 1.0000e-06\n",
            "Epoch 122/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - accuracy: 0.7941 - loss: 1.2320 - val_accuracy: 0.0200 - val_loss: 4.8725 - learning_rate: 1.0000e-06\n",
            "Epoch 123/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step - accuracy: 0.7947 - loss: 1.2102 - val_accuracy: 0.0200 - val_loss: 4.8828 - learning_rate: 1.0000e-06\n",
            "Epoch 124/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - accuracy: 0.8301 - loss: 1.1564 - val_accuracy: 0.0200 - val_loss: 4.8940 - learning_rate: 1.0000e-06\n",
            "Epoch 125/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.7386 - loss: 1.2502 - val_accuracy: 0.0200 - val_loss: 4.9055 - learning_rate: 1.0000e-06\n",
            "Epoch 126/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step - accuracy: 0.7505 - loss: 1.2508 - val_accuracy: 0.0200 - val_loss: 4.9189 - learning_rate: 1.0000e-06\n",
            "Epoch 127/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7835 - loss: 1.2194 - val_accuracy: 0.0200 - val_loss: 4.9296 - learning_rate: 1.0000e-06\n",
            "Epoch 128/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7810 - loss: 1.1891 - val_accuracy: 0.0200 - val_loss: 4.9416 - learning_rate: 1.0000e-06\n",
            "Epoch 129/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.8024 - loss: 1.2081 - val_accuracy: 0.0200 - val_loss: 4.9524 - learning_rate: 1.0000e-06\n",
            "Epoch 130/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.7765 - loss: 1.1795 - val_accuracy: 0.0200 - val_loss: 4.9656 - learning_rate: 1.0000e-06\n",
            "Epoch 131/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7630 - loss: 1.2475 - val_accuracy: 0.0200 - val_loss: 4.9776 - learning_rate: 1.0000e-06\n",
            "Epoch 132/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - accuracy: 0.7964 - loss: 1.1852 - val_accuracy: 0.0200 - val_loss: 4.9891 - learning_rate: 1.0000e-06\n",
            "Epoch 133/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7695 - loss: 1.2293 - val_accuracy: 0.0200 - val_loss: 5.0019 - learning_rate: 1.0000e-06\n",
            "Epoch 134/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.8061 - loss: 1.1506 - val_accuracy: 0.0200 - val_loss: 5.0138 - learning_rate: 1.0000e-06\n",
            "Epoch 135/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.7296 - loss: 1.3175 - val_accuracy: 0.0200 - val_loss: 5.0254 - learning_rate: 1.0000e-06\n",
            "Epoch 136/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.8004 - loss: 1.2300 - val_accuracy: 0.0200 - val_loss: 5.0360 - learning_rate: 1.0000e-06\n",
            "Epoch 137/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.8175 - loss: 1.1675 - val_accuracy: 0.0200 - val_loss: 5.0474 - learning_rate: 1.0000e-06\n",
            "Epoch 138/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.7813 - loss: 1.1806 - val_accuracy: 0.0200 - val_loss: 5.0574 - learning_rate: 1.0000e-06\n",
            "Epoch 139/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.8231 - loss: 1.2005 - val_accuracy: 0.0200 - val_loss: 5.0708 - learning_rate: 1.0000e-06\n",
            "Epoch 140/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.7515 - loss: 1.2943 - val_accuracy: 0.0200 - val_loss: 5.0812 - learning_rate: 1.0000e-06\n",
            "Epoch 141/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.8342 - loss: 1.1881 - val_accuracy: 0.0200 - val_loss: 5.0929 - learning_rate: 1.0000e-06\n",
            "Epoch 142/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.8238 - loss: 1.1822 - val_accuracy: 0.0200 - val_loss: 5.1056 - learning_rate: 1.0000e-06\n",
            "Epoch 143/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7837 - loss: 1.1930 - val_accuracy: 0.0200 - val_loss: 5.1149 - learning_rate: 1.0000e-06\n",
            "Epoch 144/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7685 - loss: 1.1531 - val_accuracy: 0.0200 - val_loss: 5.1253 - learning_rate: 1.0000e-06\n",
            "Epoch 145/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7625 - loss: 1.2535 - val_accuracy: 0.0200 - val_loss: 5.1348 - learning_rate: 1.0000e-06\n",
            "Epoch 146/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.8375 - loss: 1.1115 - val_accuracy: 0.0200 - val_loss: 5.1471 - learning_rate: 1.0000e-06\n",
            "Epoch 147/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.7828 - loss: 1.2547 - val_accuracy: 0.0200 - val_loss: 5.1589 - learning_rate: 1.0000e-06\n",
            "Epoch 148/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7783 - loss: 1.2432 - val_accuracy: 0.0000e+00 - val_loss: 5.1689 - learning_rate: 1.0000e-06\n",
            "Epoch 149/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7879 - loss: 1.2164 - val_accuracy: 0.0000e+00 - val_loss: 5.1775 - learning_rate: 1.0000e-06\n",
            "Epoch 150/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 0.7564 - loss: 1.2662 - val_accuracy: 0.0000e+00 - val_loss: 5.1880 - learning_rate: 1.0000e-06\n",
            "Epoch 151/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.7515 - loss: 1.2744 - val_accuracy: 0.0000e+00 - val_loss: 5.2010 - learning_rate: 1.0000e-06\n",
            "Epoch 152/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 0.8214 - loss: 1.1998 - val_accuracy: 0.0000e+00 - val_loss: 5.2131 - learning_rate: 1.0000e-06\n",
            "Epoch 153/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7471 - loss: 1.2591 - val_accuracy: 0.0000e+00 - val_loss: 5.2247 - learning_rate: 1.0000e-06\n",
            "Epoch 154/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.8284 - loss: 1.1517 - val_accuracy: 0.0000e+00 - val_loss: 5.2351 - learning_rate: 1.0000e-06\n",
            "Epoch 155/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.7527 - loss: 1.2562 - val_accuracy: 0.0000e+00 - val_loss: 5.2470 - learning_rate: 1.0000e-06\n",
            "Epoch 156/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.8300 - loss: 1.1308 - val_accuracy: 0.0000e+00 - val_loss: 5.2555 - learning_rate: 1.0000e-06\n",
            "Epoch 157/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.8054 - loss: 1.1817 - val_accuracy: 0.0000e+00 - val_loss: 5.2678 - learning_rate: 1.0000e-06\n",
            "Epoch 158/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8393 - loss: 1.1002 - val_accuracy: 0.0000e+00 - val_loss: 5.2775 - learning_rate: 1.0000e-06\n",
            "Epoch 159/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8191 - loss: 1.1865 - val_accuracy: 0.0000e+00 - val_loss: 5.2848 - learning_rate: 1.0000e-06\n",
            "Epoch 160/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7714 - loss: 1.2741 - val_accuracy: 0.0000e+00 - val_loss: 5.2950 - learning_rate: 1.0000e-06\n",
            "Epoch 161/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.8324 - loss: 1.1678 - val_accuracy: 0.0000e+00 - val_loss: 5.3041 - learning_rate: 1.0000e-06\n",
            "Epoch 162/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259ms/step - accuracy: 0.7464 - loss: 1.2511 - val_accuracy: 0.0000e+00 - val_loss: 5.3135 - learning_rate: 1.0000e-06\n",
            "Epoch 163/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7910 - loss: 1.1778 - val_accuracy: 0.0000e+00 - val_loss: 5.3244 - learning_rate: 1.0000e-06\n",
            "Epoch 164/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7681 - loss: 1.3105 - val_accuracy: 0.0000e+00 - val_loss: 5.3330 - learning_rate: 1.0000e-06\n",
            "Epoch 165/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7835 - loss: 1.2461 - val_accuracy: 0.0000e+00 - val_loss: 5.3431 - learning_rate: 1.0000e-06\n",
            "Epoch 166/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.8257 - loss: 1.1895 - val_accuracy: 0.0000e+00 - val_loss: 5.3527 - learning_rate: 1.0000e-06\n",
            "Epoch 167/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8256 - loss: 1.1021 - val_accuracy: 0.0000e+00 - val_loss: 5.3643 - learning_rate: 1.0000e-06\n",
            "Epoch 168/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.8055 - loss: 1.1635 - val_accuracy: 0.0000e+00 - val_loss: 5.3731 - learning_rate: 1.0000e-06\n",
            "Epoch 169/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.8456 - loss: 1.1613 - val_accuracy: 0.0000e+00 - val_loss: 5.3783 - learning_rate: 1.0000e-06\n",
            "Epoch 170/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - accuracy: 0.7580 - loss: 1.2380 - val_accuracy: 0.0000e+00 - val_loss: 5.3842 - learning_rate: 1.0000e-06\n",
            "Epoch 171/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.7934 - loss: 1.1891 - val_accuracy: 0.0000e+00 - val_loss: 5.3904 - learning_rate: 1.0000e-06\n",
            "Epoch 172/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.8205 - loss: 1.1791 - val_accuracy: 0.0000e+00 - val_loss: 5.3977 - learning_rate: 1.0000e-06\n",
            "Epoch 173/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7393 - loss: 1.2337 - val_accuracy: 0.0000e+00 - val_loss: 5.4041 - learning_rate: 1.0000e-06\n",
            "Epoch 174/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.7905 - loss: 1.2183 - val_accuracy: 0.0000e+00 - val_loss: 5.4102 - learning_rate: 1.0000e-06\n",
            "Epoch 175/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7579 - loss: 1.2228 - val_accuracy: 0.0000e+00 - val_loss: 5.4170 - learning_rate: 1.0000e-06\n",
            "Epoch 176/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8406 - loss: 1.1371 - val_accuracy: 0.0000e+00 - val_loss: 5.4222 - learning_rate: 1.0000e-06\n",
            "Epoch 177/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.7837 - loss: 1.2062 - val_accuracy: 0.0000e+00 - val_loss: 5.4271 - learning_rate: 1.0000e-06\n",
            "Epoch 178/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8492 - loss: 1.1797 - val_accuracy: 0.0000e+00 - val_loss: 5.4320 - learning_rate: 1.0000e-06\n",
            "Epoch 179/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - accuracy: 0.7869 - loss: 1.2393 - val_accuracy: 0.0000e+00 - val_loss: 5.4403 - learning_rate: 1.0000e-06\n",
            "Epoch 180/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 429ms/step - accuracy: 0.8006 - loss: 1.1982 - val_accuracy: 0.0000e+00 - val_loss: 5.4433 - learning_rate: 1.0000e-06\n",
            "Epoch 181/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258ms/step - accuracy: 0.7484 - loss: 1.2139 - val_accuracy: 0.0000e+00 - val_loss: 5.4472 - learning_rate: 1.0000e-06\n",
            "Epoch 182/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.7923 - loss: 1.2186 - val_accuracy: 0.0000e+00 - val_loss: 5.4519 - learning_rate: 1.0000e-06\n",
            "Epoch 183/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.8163 - loss: 1.1632 - val_accuracy: 0.0000e+00 - val_loss: 5.4568 - learning_rate: 1.0000e-06\n",
            "Epoch 184/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7642 - loss: 1.2710 - val_accuracy: 0.0000e+00 - val_loss: 5.4631 - learning_rate: 1.0000e-06\n",
            "Epoch 185/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.8183 - loss: 1.2017 - val_accuracy: 0.0000e+00 - val_loss: 5.4689 - learning_rate: 1.0000e-06\n",
            "Epoch 186/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7772 - loss: 1.2108 - val_accuracy: 0.0000e+00 - val_loss: 5.4701 - learning_rate: 1.0000e-06\n",
            "Epoch 187/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.8496 - loss: 1.1243 - val_accuracy: 0.0000e+00 - val_loss: 5.4706 - learning_rate: 1.0000e-06\n",
            "Epoch 188/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.8023 - loss: 1.2004 - val_accuracy: 0.0000e+00 - val_loss: 5.4769 - learning_rate: 1.0000e-06\n",
            "Epoch 189/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7920 - loss: 1.2239 - val_accuracy: 0.0000e+00 - val_loss: 5.4824 - learning_rate: 1.0000e-06\n",
            "Epoch 190/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - accuracy: 0.7310 - loss: 1.2605 - val_accuracy: 0.0000e+00 - val_loss: 5.4874 - learning_rate: 1.0000e-06\n",
            "Epoch 191/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277ms/step - accuracy: 0.7937 - loss: 1.1912 - val_accuracy: 0.0000e+00 - val_loss: 5.4919 - learning_rate: 1.0000e-06\n",
            "Epoch 192/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.7901 - loss: 1.2162 - val_accuracy: 0.0000e+00 - val_loss: 5.4942 - learning_rate: 1.0000e-06\n",
            "Epoch 193/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.8193 - loss: 1.1904 - val_accuracy: 0.0000e+00 - val_loss: 5.5013 - learning_rate: 1.0000e-06\n",
            "Epoch 194/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7842 - loss: 1.2467 - val_accuracy: 0.0000e+00 - val_loss: 5.5034 - learning_rate: 1.0000e-06\n",
            "Epoch 195/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.7801 - loss: 1.1947 - val_accuracy: 0.0000e+00 - val_loss: 5.5096 - learning_rate: 1.0000e-06\n",
            "Epoch 196/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7656 - loss: 1.2182 - val_accuracy: 0.0000e+00 - val_loss: 5.5139 - learning_rate: 1.0000e-06\n",
            "Epoch 197/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.7739 - loss: 1.2420 - val_accuracy: 0.0000e+00 - val_loss: 5.5163 - learning_rate: 1.0000e-06\n",
            "Epoch 198/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - accuracy: 0.7802 - loss: 1.2232 - val_accuracy: 0.0000e+00 - val_loss: 5.5200 - learning_rate: 1.0000e-06\n",
            "Epoch 199/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.8006 - loss: 1.1272 - val_accuracy: 0.0000e+00 - val_loss: 5.5224 - learning_rate: 1.0000e-06\n",
            "Epoch 200/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.8161 - loss: 1.1788 - val_accuracy: 0.0000e+00 - val_loss: 5.5250 - learning_rate: 1.0000e-06\n",
            "Epoch 201/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 266ms/step - accuracy: 0.7153 - loss: 1.3555 - val_accuracy: 0.0000e+00 - val_loss: 5.5297 - learning_rate: 1.0000e-06\n",
            "Epoch 202/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.7804 - loss: 1.2276 - val_accuracy: 0.0000e+00 - val_loss: 5.5319 - learning_rate: 1.0000e-06\n",
            "Epoch 203/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7851 - loss: 1.1911 - val_accuracy: 0.0000e+00 - val_loss: 5.5336 - learning_rate: 1.0000e-06\n",
            "Epoch 204/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8054 - loss: 1.2247 - val_accuracy: 0.0000e+00 - val_loss: 5.5368 - learning_rate: 1.0000e-06\n",
            "Epoch 205/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step - accuracy: 0.7712 - loss: 1.2055 - val_accuracy: 0.0000e+00 - val_loss: 5.5387 - learning_rate: 1.0000e-06\n",
            "Epoch 206/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.7721 - loss: 1.2695 - val_accuracy: 0.0000e+00 - val_loss: 5.5419 - learning_rate: 1.0000e-06\n",
            "Epoch 207/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step - accuracy: 0.7785 - loss: 1.2268 - val_accuracy: 0.0000e+00 - val_loss: 5.5470 - learning_rate: 1.0000e-06\n",
            "Epoch 208/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.7497 - loss: 1.2328 - val_accuracy: 0.0000e+00 - val_loss: 5.5452 - learning_rate: 1.0000e-06\n",
            "Epoch 209/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399ms/step - accuracy: 0.7859 - loss: 1.1597 - val_accuracy: 0.0000e+00 - val_loss: 5.5454 - learning_rate: 1.0000e-06\n",
            "Epoch 210/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 265ms/step - accuracy: 0.8109 - loss: 1.1415 - val_accuracy: 0.0000e+00 - val_loss: 5.5481 - learning_rate: 1.0000e-06\n",
            "Epoch 211/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.7690 - loss: 1.2518 - val_accuracy: 0.0000e+00 - val_loss: 5.5527 - learning_rate: 1.0000e-06\n",
            "Epoch 212/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.8152 - loss: 1.1719 - val_accuracy: 0.0000e+00 - val_loss: 5.5531 - learning_rate: 1.0000e-06\n",
            "Epoch 213/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.8113 - loss: 1.1880 - val_accuracy: 0.0000e+00 - val_loss: 5.5570 - learning_rate: 1.0000e-06\n",
            "Epoch 214/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.7900 - loss: 1.2382 - val_accuracy: 0.0000e+00 - val_loss: 5.5602 - learning_rate: 1.0000e-06\n",
            "Epoch 215/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7880 - loss: 1.1988 - val_accuracy: 0.0000e+00 - val_loss: 5.5622 - learning_rate: 1.0000e-06\n",
            "Epoch 216/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.7858 - loss: 1.1997 - val_accuracy: 0.0000e+00 - val_loss: 5.5644 - learning_rate: 1.0000e-06\n",
            "Epoch 217/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.8084 - loss: 1.1746 - val_accuracy: 0.0000e+00 - val_loss: 5.5687 - learning_rate: 1.0000e-06\n",
            "Epoch 218/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.7912 - loss: 1.1721 - val_accuracy: 0.0000e+00 - val_loss: 5.5675 - learning_rate: 1.0000e-06\n",
            "Epoch 219/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - accuracy: 0.8689 - loss: 1.1020 - val_accuracy: 0.0000e+00 - val_loss: 5.5676 - learning_rate: 1.0000e-06\n",
            "Epoch 220/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.8322 - loss: 1.1338 - val_accuracy: 0.0000e+00 - val_loss: 5.5683 - learning_rate: 1.0000e-06\n",
            "Epoch 221/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7479 - loss: 1.2809 - val_accuracy: 0.0000e+00 - val_loss: 5.5681 - learning_rate: 1.0000e-06\n",
            "Epoch 222/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step - accuracy: 0.8579 - loss: 1.1392 - val_accuracy: 0.0000e+00 - val_loss: 5.5691 - learning_rate: 1.0000e-06\n",
            "Epoch 223/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7778 - loss: 1.2246 - val_accuracy: 0.0000e+00 - val_loss: 5.5703 - learning_rate: 1.0000e-06\n",
            "Epoch 224/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step - accuracy: 0.7837 - loss: 1.2225 - val_accuracy: 0.0000e+00 - val_loss: 5.5720 - learning_rate: 1.0000e-06\n",
            "Epoch 225/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7581 - loss: 1.3313 - val_accuracy: 0.0000e+00 - val_loss: 5.5736 - learning_rate: 1.0000e-06\n",
            "Epoch 226/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.7785 - loss: 1.1987 - val_accuracy: 0.0000e+00 - val_loss: 5.5742 - learning_rate: 1.0000e-06\n",
            "Epoch 227/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.8467 - loss: 1.1379 - val_accuracy: 0.0000e+00 - val_loss: 5.5748 - learning_rate: 1.0000e-06\n",
            "Epoch 228/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 319ms/step - accuracy: 0.7998 - loss: 1.2059 - val_accuracy: 0.0000e+00 - val_loss: 5.5781 - learning_rate: 1.0000e-06\n",
            "Epoch 229/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.7695 - loss: 1.2200 - val_accuracy: 0.0000e+00 - val_loss: 5.5790 - learning_rate: 1.0000e-06\n",
            "Epoch 230/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.8158 - loss: 1.1515 - val_accuracy: 0.0000e+00 - val_loss: 5.5772 - learning_rate: 1.0000e-06\n",
            "Epoch 231/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.8020 - loss: 1.2288 - val_accuracy: 0.0000e+00 - val_loss: 5.5801 - learning_rate: 1.0000e-06\n",
            "Epoch 232/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.7819 - loss: 1.2103 - val_accuracy: 0.0000e+00 - val_loss: 5.5844 - learning_rate: 1.0000e-06\n",
            "Epoch 233/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8191 - loss: 1.1662 - val_accuracy: 0.0000e+00 - val_loss: 5.5829 - learning_rate: 1.0000e-06\n",
            "Epoch 234/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.8156 - loss: 1.2254 - val_accuracy: 0.0000e+00 - val_loss: 5.5835 - learning_rate: 1.0000e-06\n",
            "Epoch 235/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step - accuracy: 0.7918 - loss: 1.2308 - val_accuracy: 0.0000e+00 - val_loss: 5.5845 - learning_rate: 1.0000e-06\n",
            "Epoch 236/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.7818 - loss: 1.2466 - val_accuracy: 0.0000e+00 - val_loss: 5.5825 - learning_rate: 1.0000e-06\n",
            "Epoch 237/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262ms/step - accuracy: 0.8198 - loss: 1.1779 - val_accuracy: 0.0000e+00 - val_loss: 5.5795 - learning_rate: 1.0000e-06\n",
            "Epoch 238/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.7743 - loss: 1.2088 - val_accuracy: 0.0000e+00 - val_loss: 5.5799 - learning_rate: 1.0000e-06\n",
            "Epoch 239/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.7775 - loss: 1.2562 - val_accuracy: 0.0000e+00 - val_loss: 5.5780 - learning_rate: 1.0000e-06\n",
            "Epoch 240/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.7681 - loss: 1.2864 - val_accuracy: 0.0000e+00 - val_loss: 5.5803 - learning_rate: 1.0000e-06\n",
            "Epoch 241/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7862 - loss: 1.2153 - val_accuracy: 0.0000e+00 - val_loss: 5.5821 - learning_rate: 1.0000e-06\n",
            "Epoch 242/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.7920 - loss: 1.2171 - val_accuracy: 0.0000e+00 - val_loss: 5.5838 - learning_rate: 1.0000e-06\n",
            "Epoch 243/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7629 - loss: 1.2935 - val_accuracy: 0.0000e+00 - val_loss: 5.5856 - learning_rate: 1.0000e-06\n",
            "Epoch 244/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.7552 - loss: 1.2402 - val_accuracy: 0.0000e+00 - val_loss: 5.5867 - learning_rate: 1.0000e-06\n",
            "Epoch 245/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7785 - loss: 1.2370 - val_accuracy: 0.0000e+00 - val_loss: 5.5853 - learning_rate: 1.0000e-06\n",
            "Epoch 246/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 261ms/step - accuracy: 0.8117 - loss: 1.1733 - val_accuracy: 0.0000e+00 - val_loss: 5.5857 - learning_rate: 1.0000e-06\n",
            "Epoch 247/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7339 - loss: 1.2692 - val_accuracy: 0.0000e+00 - val_loss: 5.5855 - learning_rate: 1.0000e-06\n",
            "Epoch 248/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.8100 - loss: 1.1581 - val_accuracy: 0.0000e+00 - val_loss: 5.5848 - learning_rate: 1.0000e-06\n",
            "Epoch 249/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.7911 - loss: 1.1593 - val_accuracy: 0.0000e+00 - val_loss: 5.5848 - learning_rate: 1.0000e-06\n",
            "Epoch 250/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.7463 - loss: 1.2457 - val_accuracy: 0.0000e+00 - val_loss: 5.5883 - learning_rate: 1.0000e-06\n",
            "Epoch 251/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.8073 - loss: 1.1848 - val_accuracy: 0.0000e+00 - val_loss: 5.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 252/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.8117 - loss: 1.1947 - val_accuracy: 0.0000e+00 - val_loss: 5.5884 - learning_rate: 1.0000e-06\n",
            "Epoch 253/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.7707 - loss: 1.2713 - val_accuracy: 0.0000e+00 - val_loss: 5.5892 - learning_rate: 1.0000e-06\n",
            "Epoch 254/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.7976 - loss: 1.1673 - val_accuracy: 0.0000e+00 - val_loss: 5.5887 - learning_rate: 1.0000e-06\n",
            "Epoch 255/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 401ms/step - accuracy: 0.7599 - loss: 1.2243 - val_accuracy: 0.0000e+00 - val_loss: 5.5909 - learning_rate: 1.0000e-06\n",
            "Epoch 256/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.8105 - loss: 1.2229 - val_accuracy: 0.0000e+00 - val_loss: 5.5923 - learning_rate: 1.0000e-06\n",
            "Epoch 257/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.8128 - loss: 1.1698 - val_accuracy: 0.0000e+00 - val_loss: 5.5907 - learning_rate: 1.0000e-06\n",
            "Epoch 258/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 0.8176 - loss: 1.1654 - val_accuracy: 0.0000e+00 - val_loss: 5.5912 - learning_rate: 1.0000e-06\n",
            "Epoch 259/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7986 - loss: 1.2090 - val_accuracy: 0.0000e+00 - val_loss: 5.5903 - learning_rate: 1.0000e-06\n",
            "Epoch 260/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7588 - loss: 1.2827 - val_accuracy: 0.0000e+00 - val_loss: 5.5916 - learning_rate: 1.0000e-06\n",
            "Epoch 261/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.7980 - loss: 1.2352 - val_accuracy: 0.0000e+00 - val_loss: 5.5891 - learning_rate: 1.0000e-06\n",
            "Epoch 262/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7775 - loss: 1.2584 - val_accuracy: 0.0000e+00 - val_loss: 5.5888 - learning_rate: 1.0000e-06\n",
            "Epoch 263/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8288 - loss: 1.1284 - val_accuracy: 0.0000e+00 - val_loss: 5.5885 - learning_rate: 1.0000e-06\n",
            "Epoch 264/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.8171 - loss: 1.1843 - val_accuracy: 0.0000e+00 - val_loss: 5.5884 - learning_rate: 1.0000e-06\n",
            "Epoch 265/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step - accuracy: 0.8057 - loss: 1.2037 - val_accuracy: 0.0000e+00 - val_loss: 5.5892 - learning_rate: 1.0000e-06\n",
            "Epoch 266/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.7526 - loss: 1.2854 - val_accuracy: 0.0000e+00 - val_loss: 5.5917 - learning_rate: 1.0000e-06\n",
            "Epoch 267/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - accuracy: 0.7826 - loss: 1.1768 - val_accuracy: 0.0000e+00 - val_loss: 5.5946 - learning_rate: 1.0000e-06\n",
            "Epoch 268/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.8310 - loss: 1.1391 - val_accuracy: 0.0000e+00 - val_loss: 5.5939 - learning_rate: 1.0000e-06\n",
            "Epoch 269/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.7334 - loss: 1.3018 - val_accuracy: 0.0000e+00 - val_loss: 5.5973 - learning_rate: 1.0000e-06\n",
            "Epoch 270/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.8471 - loss: 1.1021 - val_accuracy: 0.0000e+00 - val_loss: 5.5981 - learning_rate: 1.0000e-06\n",
            "Epoch 271/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 0.7544 - loss: 1.2465 - val_accuracy: 0.0000e+00 - val_loss: 5.6003 - learning_rate: 1.0000e-06\n",
            "Epoch 272/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.8126 - loss: 1.1712 - val_accuracy: 0.0000e+00 - val_loss: 5.6022 - learning_rate: 1.0000e-06\n",
            "Epoch 273/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 0.8197 - loss: 1.1475 - val_accuracy: 0.0000e+00 - val_loss: 5.6041 - learning_rate: 1.0000e-06\n",
            "Epoch 274/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277ms/step - accuracy: 0.7864 - loss: 1.2411 - val_accuracy: 0.0000e+00 - val_loss: 5.6070 - learning_rate: 1.0000e-06\n",
            "Epoch 275/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.8336 - loss: 1.1345 - val_accuracy: 0.0000e+00 - val_loss: 5.6049 - learning_rate: 1.0000e-06\n",
            "Epoch 276/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 267ms/step - accuracy: 0.7474 - loss: 1.2915 - val_accuracy: 0.0000e+00 - val_loss: 5.6053 - learning_rate: 1.0000e-06\n",
            "Epoch 277/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.8001 - loss: 1.1705 - val_accuracy: 0.0000e+00 - val_loss: 5.6050 - learning_rate: 1.0000e-06\n",
            "Epoch 278/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step - accuracy: 0.7829 - loss: 1.2071 - val_accuracy: 0.0000e+00 - val_loss: 5.6055 - learning_rate: 1.0000e-06\n",
            "Epoch 279/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.7699 - loss: 1.2338 - val_accuracy: 0.0000e+00 - val_loss: 5.6038 - learning_rate: 1.0000e-06\n",
            "Epoch 280/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step - accuracy: 0.8146 - loss: 1.1358 - val_accuracy: 0.0000e+00 - val_loss: 5.6042 - learning_rate: 1.0000e-06\n",
            "Epoch 281/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.7785 - loss: 1.2940 - val_accuracy: 0.0000e+00 - val_loss: 5.6033 - learning_rate: 1.0000e-06\n",
            "Epoch 282/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.7850 - loss: 1.2224 - val_accuracy: 0.0000e+00 - val_loss: 5.6033 - learning_rate: 1.0000e-06\n",
            "Epoch 283/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7669 - loss: 1.1937 - val_accuracy: 0.0000e+00 - val_loss: 5.6011 - learning_rate: 1.0000e-06\n",
            "Epoch 284/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7917 - loss: 1.1916 - val_accuracy: 0.0000e+00 - val_loss: 5.6036 - learning_rate: 1.0000e-06\n",
            "Epoch 285/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 274ms/step - accuracy: 0.8446 - loss: 1.1206 - val_accuracy: 0.0000e+00 - val_loss: 5.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 286/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 0.8000 - loss: 1.2206 - val_accuracy: 0.0000e+00 - val_loss: 5.6017 - learning_rate: 1.0000e-06\n",
            "Epoch 287/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.7919 - loss: 1.2501 - val_accuracy: 0.0000e+00 - val_loss: 5.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 288/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.8316 - loss: 1.1771 - val_accuracy: 0.0000e+00 - val_loss: 5.6018 - learning_rate: 1.0000e-06\n",
            "Epoch 289/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.7684 - loss: 1.1844 - val_accuracy: 0.0000e+00 - val_loss: 5.6002 - learning_rate: 1.0000e-06\n",
            "Epoch 290/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 0.7846 - loss: 1.1973 - val_accuracy: 0.0000e+00 - val_loss: 5.6003 - learning_rate: 1.0000e-06\n",
            "Epoch 291/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.7979 - loss: 1.1417 - val_accuracy: 0.0000e+00 - val_loss: 5.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 292/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.8654 - loss: 1.0902 - val_accuracy: 0.0000e+00 - val_loss: 5.5988 - learning_rate: 1.0000e-06\n",
            "Epoch 293/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8223 - loss: 1.1860 - val_accuracy: 0.0000e+00 - val_loss: 5.6016 - learning_rate: 1.0000e-06\n",
            "Epoch 294/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.8680 - loss: 1.1249 - val_accuracy: 0.0000e+00 - val_loss: 5.6005 - learning_rate: 1.0000e-06\n",
            "Epoch 295/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 267ms/step - accuracy: 0.8026 - loss: 1.2433 - val_accuracy: 0.0000e+00 - val_loss: 5.6002 - learning_rate: 1.0000e-06\n",
            "Epoch 296/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7529 - loss: 1.2431 - val_accuracy: 0.0000e+00 - val_loss: 5.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 297/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.7972 - loss: 1.2685 - val_accuracy: 0.0000e+00 - val_loss: 5.5983 - learning_rate: 1.0000e-06\n",
            "Epoch 298/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step - accuracy: 0.7965 - loss: 1.2812 - val_accuracy: 0.0000e+00 - val_loss: 5.5992 - learning_rate: 1.0000e-06\n",
            "Epoch 299/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.8071 - loss: 1.2096 - val_accuracy: 0.0000e+00 - val_loss: 5.6004 - learning_rate: 1.0000e-06\n",
            "Epoch 300/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 0.8079 - loss: 1.1644 - val_accuracy: 0.0000e+00 - val_loss: 5.5998 - learning_rate: 1.0000e-06\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n",
            "\n",
            "验证集命中率：37.00%\n",
            "{'期号': '2024261', '预测前 16 特别号码': [41, 20, 11, 15, 44, 29, 42, 10, 17, 32, 1, 19, 37, 6, 27, 47], '实际特别号码': 1, '命中': '是'}\n",
            "{'期号': '2024262', '预测前 16 特别号码': [41, 32, 20, 15, 42, 44, 10, 11, 29, 1, 25, 17, 39, 47, 6, 45], '实际特别号码': 44, '命中': '是'}\n",
            "{'期号': '2024263', '预测前 16 特别号码': [32, 15, 10, 42, 41, 20, 1, 44, 45, 11, 28, 14, 6, 25, 22, 9], '实际特别号码': 13, '命中': '否'}\n",
            "{'期号': '2024264', '预测前 16 特别号码': [32, 10, 15, 42, 41, 45, 20, 14, 44, 6, 22, 11, 19, 1, 25, 40], '实际特别号码': 30, '命中': '否'}\n",
            "{'期号': '2024265', '预测前 16 特别号码': [32, 10, 15, 42, 11, 6, 44, 14, 16, 41, 5, 9, 20, 28, 25, 1], '实际特别号码': 16, '命中': '是'}\n",
            "{'期号': '2024266', '预测前 16 特别号码': [32, 10, 15, 16, 14, 42, 28, 6, 45, 5, 11, 1, 9, 44, 25, 20], '实际特别号码': 27, '命中': '否'}\n",
            "{'期号': '2024267', '预测前 16 特别号码': [32, 10, 15, 42, 16, 40, 45, 49, 28, 35, 22, 44, 25, 14, 9, 6], '实际特别号码': 12, '命中': '否'}\n",
            "{'期号': '2024268', '预测前 16 特别号码': [15, 42, 32, 40, 2, 49, 16, 10, 22, 45, 35, 6, 9, 25, 41, 43], '实际特别号码': 22, '命中': '是'}\n",
            "{'期号': '2024269', '预测前 16 特别号码': [2, 15, 40, 49, 16, 43, 32, 42, 22, 28, 12, 6, 48, 31, 35, 41], '实际特别号码': 11, '命中': '否'}\n",
            "{'期号': '2024270', '预测前 16 特别号码': [43, 6, 2, 40, 31, 11, 48, 49, 42, 33, 13, 35, 10, 15, 37, 25], '实际特别号码': 42, '命中': '是'}\n",
            "{'期号': '2024271', '预测前 16 特别号码': [2, 43, 6, 37, 31, 11, 13, 46, 48, 29, 45, 35, 5, 49, 40, 12], '实际特别号码': 40, '命中': '是'}\n",
            "{'期号': '2024272', '预测前 16 特别号码': [6, 37, 13, 2, 34, 31, 29, 41, 46, 11, 20, 48, 33, 49, 43, 39], '实际特别号码': 30, '命中': '否'}\n",
            "{'期号': '2024273', '预测前 16 特别号码': [37, 34, 2, 29, 33, 31, 41, 6, 13, 19, 39, 20, 4, 44, 46, 23], '实际特别号码': 41, '命中': '是'}\n",
            "{'期号': '2024274', '预测前 16 特别号码': [33, 31, 19, 4, 39, 37, 41, 20, 29, 2, 34, 6, 42, 13, 27, 24], '实际特别号码': 49, '命中': '否'}\n",
            "{'期号': '2024275', '预测前 16 特别号码': [19, 4, 37, 31, 33, 39, 41, 34, 20, 2, 24, 6, 29, 27, 42, 21], '实际特别号码': 41, '命中': '是'}\n",
            "{'期号': '2024276', '预测前 16 特别号码': [31, 39, 19, 4, 33, 42, 37, 20, 41, 48, 34, 24, 29, 27, 28, 15], '实际特别号码': 29, '命中': '是'}\n",
            "{'期号': '2024277', '预测前 16 特别号码': [31, 4, 42, 39, 37, 19, 33, 6, 20, 34, 7, 24, 29, 15, 41, 28], '实际特别号码': 26, '命中': '否'}\n",
            "{'期号': '2024278', '预测前 16 特别号码': [39, 42, 37, 15, 4, 31, 19, 6, 29, 20, 10, 34, 41, 25, 46, 3], '实际特别号码': 7, '命中': '否'}\n",
            "{'期号': '2024279', '预测前 16 特别号码': [39, 4, 15, 42, 29, 28, 10, 6, 31, 37, 5, 20, 46, 21, 34, 2], '实际特别号码': 40, '命中': '否'}\n",
            "{'期号': '2024280', '预测前 16 特别号码': [28, 15, 39, 21, 4, 3, 2, 29, 17, 46, 1, 10, 16, 6, 42, 11], '实际特别号码': 22, '命中': '否'}\n",
            "{'期号': '2024281', '预测前 16 特别号码': [28, 15, 2, 29, 17, 42, 39, 11, 20, 27, 21, 6, 43, 1, 19, 41], '实际特别号码': 43, '命中': '是'}\n",
            "{'期号': '2024282', '预测前 16 特别号码': [17, 28, 3, 43, 11, 2, 21, 15, 29, 37, 39, 6, 1, 40, 19, 12], '实际特别号码': 13, '命中': '否'}\n",
            "{'期号': '2024283', '预测前 16 特别号码': [17, 43, 28, 3, 21, 6, 2, 37, 1, 39, 29, 19, 22, 11, 40, 12], '实际特别号码': 47, '命中': '否'}\n",
            "{'期号': '2024284', '预测前 16 特别号码': [6, 29, 17, 43, 19, 37, 1, 22, 41, 27, 35, 3, 11, 28, 2, 20], '实际特别号码': 27, '命中': '是'}\n",
            "{'期号': '2024285', '预测前 16 特别号码': [22, 17, 35, 1, 19, 21, 29, 6, 37, 41, 43, 28, 2, 27, 5, 39], '实际特别号码': 21, '命中': '是'}\n",
            "{'期号': '2024286', '预测前 16 特别号码': [22, 19, 29, 35, 41, 6, 34, 37, 2, 27, 44, 1, 39, 21, 43, 20], '实际特别号码': 45, '命中': '否'}\n",
            "{'期号': '2024287', '预测前 16 特别号码': [22, 35, 41, 6, 34, 29, 19, 10, 20, 27, 32, 37, 40, 44, 43, 33], '实际特别号码': 40, '命中': '是'}\n",
            "{'期号': '2024288', '预测前 16 特别号码': [41, 44, 29, 42, 35, 20, 32, 10, 19, 34, 40, 45, 39, 37, 28, 13], '实际特别号码': 26, '命中': '否'}\n",
            "{'期号': '2024289', '预测前 16 特别号码': [42, 41, 20, 45, 10, 29, 15, 44, 35, 28, 13, 34, 32, 39, 14, 46], '实际特别号码': 4, '命中': '否'}\n",
            "{'期号': '2024290', '预测前 16 特别号码': [42, 20, 45, 44, 13, 28, 41, 19, 34, 46, 29, 10, 15, 36, 37, 35], '实际特别号码': 11, '命中': '否'}\n",
            "{'期号': '2024291', '预测前 16 特别号码': [20, 28, 44, 10, 42, 13, 2, 45, 15, 34, 46, 1, 22, 33, 19, 6], '实际特别号码': 14, '命中': '否'}\n",
            "{'期号': '2024292', '预测前 16 特别号码': [20, 10, 28, 45, 43, 13, 6, 1, 2, 22, 42, 34, 33, 49, 15, 41], '实际特别号码': 44, '命中': '否'}\n",
            "{'期号': '2024293', '预测前 16 特别号码': [20, 43, 6, 45, 22, 10, 33, 3, 27, 1, 13, 42, 19, 41, 2, 28], '实际特别号码': 30, '命中': '否'}\n",
            "{'期号': '2024294', '预测前 16 特别号码': [43, 6, 22, 20, 10, 45, 3, 27, 19, 41, 33, 15, 13, 2, 8, 49], '实际特别号码': 48, '命中': '否'}\n",
            "{'期号': '2024295', '预测前 16 特别号码': [6, 43, 10, 27, 20, 19, 3, 22, 49, 45, 41, 40, 1, 37, 35, 24], '实际特别号码': 24, '命中': '是'}\n",
            "{'期号': '2024296', '预测前 16 特别号码': [10, 6, 43, 27, 20, 19, 3, 41, 49, 22, 34, 24, 11, 45, 8, 28], '实际特别号码': 9, '命中': '否'}\n",
            "{'期号': '2024297', '预测前 16 特别号码': [43, 10, 6, 27, 25, 19, 41, 31, 22, 49, 34, 35, 12, 40, 24, 33], '实际特别号码': 49, '命中': '是'}\n",
            "{'期号': '2024298', '预测前 16 特别号码': [43, 6, 31, 25, 46, 27, 19, 11, 34, 12, 37, 29, 3, 10, 48, 24], '实际特别号码': 44, '命中': '否'}\n",
            "{'期号': '2024299', '预测前 16 特别号码': [29, 25, 31, 6, 11, 19, 42, 37, 10, 4, 34, 43, 20, 46, 15, 41], '实际特别号码': 21, '命中': '否'}\n",
            "{'期号': '2024300', '预测前 16 特别号码': [42, 29, 4, 11, 46, 37, 6, 31, 19, 10, 40, 23, 47, 20, 25, 13], '实际特别号码': 46, '命中': '是'}\n",
            "{'期号': '2024301', '预测前 16 特别号码': [42, 29, 46, 11, 6, 37, 4, 19, 40, 20, 43, 8, 13, 49, 23, 34], '实际特别号码': 16, '命中': '否'}\n",
            "{'期号': '2024302', '预测前 16 特别号码': [42, 46, 29, 43, 8, 49, 6, 37, 20, 44, 13, 11, 15, 4, 35, 48], '实际特别号码': 24, '命中': '否'}\n",
            "{'期号': '2024303', '预测前 16 特别号码': [29, 43, 46, 42, 25, 49, 8, 48, 37, 6, 15, 2, 13, 44, 11, 19], '实际特别号码': 38, '命中': '否'}\n",
            "{'期号': '2024304', '预测前 16 特别号码': [29, 43, 25, 6, 37, 49, 35, 13, 10, 5, 2, 46, 27, 36, 48, 8], '实际特别号码': 17, '命中': '否'}\n",
            "{'期号': '2024305', '预测前 16 特别号码': [29, 5, 6, 13, 2, 37, 35, 43, 46, 36, 48, 21, 10, 19, 8, 22], '实际特别号码': 32, '命中': '否'}\n",
            "{'期号': '2024306', '预测前 16 特别号码': [29, 5, 13, 6, 35, 37, 2, 46, 10, 36, 8, 43, 49, 48, 22, 38], '实际特别号码': 8, '命中': '是'}\n",
            "{'期号': '2024307', '预测前 16 特别号码': [5, 29, 6, 35, 13, 37, 19, 2, 36, 1, 10, 22, 49, 43, 27, 8], '实际特别号码': 3, '命中': '否'}\n",
            "{'期号': '2024308', '预测前 16 特别号码': [5, 19, 6, 35, 29, 37, 10, 2, 13, 16, 1, 49, 21, 36, 40, 12], '实际特别号码': 22, '命中': '否'}\n",
            "{'期号': '2024309', '预测前 16 特别号码': [5, 19, 16, 6, 35, 10, 37, 2, 29, 21, 36, 13, 34, 1, 12, 11], '实际特别号码': 9, '命中': '否'}\n",
            "{'期号': '2024310', '预测前 16 特别号码': [19, 16, 5, 10, 21, 32, 6, 36, 2, 29, 35, 37, 13, 46, 11, 34], '实际特别号码': 4, '命中': '否'}\n",
            "{'期号': '2024311', '预测前 16 特别号码': [19, 5, 6, 11, 32, 16, 13, 36, 10, 37, 35, 44, 28, 46, 21, 7], '实际特别号码': 21, '命中': '是'}\n",
            "{'期号': '2024312', '预测前 16 特别号码': [19, 32, 16, 11, 44, 6, 5, 35, 13, 10, 46, 7, 42, 37, 36, 34], '实际特别号码': 48, '命中': '否'}\n",
            "{'期号': '2024313', '预测前 16 特别号码': [32, 44, 11, 46, 10, 16, 35, 5, 49, 19, 42, 20, 14, 39, 7, 6], '实际特别号码': 46, '命中': '是'}\n",
            "{'期号': '2024314', '预测前 16 特别号码': [44, 32, 11, 16, 46, 42, 20, 49, 30, 10, 35, 17, 14, 19, 7, 5], '实际特别号码': 18, '命中': '否'}\n",
            "{'期号': '2024315', '预测前 16 特别号码': [44, 42, 32, 20, 17, 11, 49, 10, 45, 19, 16, 46, 29, 25, 43, 34], '实际特别号码': 35, '命中': '否'}\n",
            "{'期号': '2024316', '预测前 16 特别号码': [44, 42, 32, 17, 45, 25, 20, 10, 29, 34, 19, 49, 46, 43, 11, 16], '实际特别号码': 5, '命中': '否'}\n",
            "{'期号': '2024317', '预测前 16 特别号码': [42, 45, 25, 43, 44, 10, 29, 20, 49, 46, 37, 34, 13, 6, 19, 17], '实际特别号码': 13, '命中': '是'}\n",
            "{'期号': '2024318', '预测前 16 特别号码': [45, 25, 43, 46, 20, 19, 42, 10, 34, 37, 49, 13, 29, 24, 44, 6], '实际特别号码': 44, '命中': '是'}\n",
            "{'期号': '2024319', '预测前 16 特别号码': [25, 45, 43, 46, 10, 49, 16, 29, 19, 6, 37, 34, 42, 24, 13, 35], '实际特别号码': 41, '命中': '否'}\n",
            "{'期号': '2024320', '预测前 16 特别号码': [45, 25, 43, 10, 16, 19, 35, 6, 37, 34, 24, 20, 42, 29, 15, 33], '实际特别号码': 12, '命中': '否'}\n",
            "{'期号': '2024321', '预测前 16 特别号码': [25, 37, 10, 16, 5, 45, 6, 2, 35, 19, 29, 21, 43, 34, 36, 13], '实际特别号码': 36, '命中': '是'}\n",
            "{'期号': '2024322', '预测前 16 特别号码': [10, 25, 21, 16, 5, 37, 33, 6, 34, 45, 2, 36, 13, 29, 24, 22], '实际特别号码': 27, '命中': '否'}\n",
            "{'期号': '2024323', '预测前 16 特别号码': [21, 16, 33, 22, 10, 2, 28, 6, 37, 36, 34, 5, 13, 48, 46, 19], '实际特别号码': 39, '命中': '否'}\n",
            "{'期号': '2024324', '预测前 16 特别号码': [22, 37, 33, 21, 43, 28, 48, 6, 2, 36, 5, 31, 16, 15, 34, 17], '实际特别号码': 1, '命中': '否'}\n",
            "{'期号': '2024325', '预测前 16 特别号码': [43, 37, 48, 33, 28, 11, 31, 5, 46, 16, 6, 22, 4, 21, 15, 9], '实际特别号码': 28, '命中': '是'}\n",
            "{'期号': '2024326', '预测前 16 特别号码': [37, 5, 43, 17, 21, 6, 48, 28, 40, 12, 46, 9, 33, 39, 3, 16], '实际特别号码': 19, '命中': '否'}\n",
            "{'期号': '2024327', '预测前 16 特别号码': [46, 9, 40, 3, 5, 28, 37, 39, 17, 12, 16, 43, 21, 48, 7, 49], '实际特别号码': 41, '命中': '否'}\n",
            "{'期号': '2024328', '预测前 16 特别号码': [39, 40, 3, 16, 17, 5, 31, 7, 48, 9, 12, 4, 28, 21, 43, 37], '实际特别号码': 20, '命中': '否'}\n",
            "{'期号': '2024329', '预测前 16 特别号码': [39, 40, 17, 16, 3, 9, 7, 5, 28, 21, 30, 32, 47, 31, 48, 15], '实际特别号码': 14, '命中': '否'}\n",
            "{'期号': '2024330', '预测前 16 特别号码': [39, 17, 31, 30, 32, 9, 46, 7, 16, 4, 3, 47, 40, 25, 23, 49], '实际特别号码': 11, '命中': '否'}\n",
            "{'期号': '2024331', '预测前 16 特别号码': [39, 9, 29, 40, 25, 30, 43, 42, 17, 31, 47, 2, 16, 49, 3, 28], '实际特别号码': 6, '命中': '否'}\n",
            "{'期号': '2024332', '预测前 16 特别号码': [43, 16, 39, 3, 9, 30, 40, 25, 10, 42, 27, 15, 12, 2, 32, 22], '实际特别号码': 32, '命中': '是'}\n",
            "{'期号': '2024333', '预测前 16 特别号码': [16, 9, 43, 30, 40, 3, 25, 39, 10, 28, 12, 49, 5, 2, 15, 42], '实际特别号码': 4, '命中': '否'}\n",
            "{'期号': '2024334', '预测前 16 特别号码': [9, 16, 43, 3, 30, 40, 42, 2, 28, 39, 12, 15, 7, 17, 49, 10], '实际特别号码': 46, '命中': '否'}\n",
            "{'期号': '2024335', '预测前 16 特别号码': [9, 42, 28, 16, 3, 43, 39, 30, 17, 2, 15, 34, 12, 40, 38, 13], '实际特别号码': 34, '命中': '是'}\n",
            "{'期号': '2024336', '预测前 16 特别号码': [42, 3, 20, 9, 28, 16, 12, 34, 43, 15, 39, 19, 8, 45, 40, 17], '实际特别号码': 5, '命中': '否'}\n",
            "{'期号': '2024337', '预测前 16 特别号码': [3, 16, 40, 20, 19, 28, 42, 15, 44, 34, 9, 17, 39, 38, 12, 8], '实际特别号码': 48, '命中': '否'}\n",
            "{'期号': '2024338', '预测前 16 特别号码': [20, 44, 3, 38, 16, 10, 19, 34, 17, 42, 28, 24, 13, 49, 43, 8], '实际特别号码': 40, '命中': '否'}\n",
            "{'期号': '2024339', '预测前 16 特别号码': [20, 3, 44, 43, 24, 6, 19, 1, 10, 38, 49, 17, 33, 11, 8, 34], '实际特别号码': 38, '命中': '是'}\n",
            "{'期号': '2024340', '预测前 16 特别号码': [20, 44, 1, 3, 10, 43, 24, 6, 22, 38, 33, 13, 18, 45, 34, 17], '实际特别号码': 47, '命中': '否'}\n",
            "{'期号': '2024341', '预测前 16 特别号码': [20, 22, 1, 43, 10, 44, 3, 13, 45, 18, 17, 6, 38, 35, 24, 19], '实际特别号码': 18, '命中': '是'}\n",
            "{'期号': '2024342', '预测前 16 特别号码': [35, 22, 19, 20, 1, 27, 10, 6, 29, 3, 21, 44, 25, 43, 17, 13], '实际特别号码': 49, '命中': '否'}\n",
            "{'期号': '2024343', '预测前 16 特别号码': [25, 19, 10, 35, 29, 20, 21, 22, 17, 32, 45, 34, 13, 27, 1, 37], '实际特别号码': 45, '命中': '是'}\n",
            "{'期号': '2024344', '预测前 16 特别号码': [19, 25, 29, 21, 35, 10, 20, 17, 32, 37, 4, 1, 41, 24, 27, 34], '实际特别号码': 2, '命中': '否'}\n",
            "{'期号': '2024345', '预测前 16 特别号码': [35, 19, 20, 17, 27, 25, 41, 29, 22, 37, 1, 4, 21, 36, 32, 6], '实际特别号码': 46, '命中': '否'}\n",
            "{'期号': '2024346', '预测前 16 特别号码': [35, 25, 20, 27, 41, 19, 24, 17, 29, 4, 1, 37, 6, 42, 5, 33], '实际特别号码': 41, '命中': '是'}\n",
            "{'期号': '2024347', '预测前 16 特别号码': [35, 20, 27, 42, 1, 41, 25, 29, 10, 4, 30, 39, 24, 19, 28, 32], '实际特别号码': 28, '命中': '是'}\n",
            "{'期号': '2024348', '预测前 16 特别号码': [35, 20, 1, 9, 27, 30, 39, 41, 42, 10, 2, 28, 29, 48, 6, 4], '实际特别号码': 17, '命中': '否'}\n",
            "{'期号': '2024349', '预测前 16 特别号码': [35, 39, 20, 29, 1, 9, 30, 5, 19, 41, 2, 4, 17, 21, 6, 42], '实际特别号码': 1, '命中': '是'}\n",
            "{'期号': '2024350', '预测前 16 特别号码': [9, 39, 30, 35, 5, 29, 40, 1, 19, 2, 20, 28, 17, 21, 33, 4], '实际特别号码': 4, '命中': '是'}\n",
            "{'期号': '2024351', '预测前 16 特别号码': [19, 16, 5, 39, 21, 3, 40, 9, 29, 30, 25, 35, 47, 17, 7, 2], '实际特别号码': 27, '命中': '否'}\n",
            "{'期号': '2024352', '预测前 16 特别号码': [16, 3, 40, 39, 44, 9, 19, 25, 46, 5, 14, 30, 21, 29, 7, 28], '实际特别号码': 10, '命中': '否'}\n",
            "{'期号': '2024353', '预测前 16 特别号码': [16, 3, 32, 46, 21, 39, 40, 44, 25, 9, 28, 30, 49, 7, 10, 42], '实际特别号码': 47, '命中': '否'}\n",
            "{'期号': '2024354', '预测前 16 特别号码': [16, 32, 3, 46, 25, 9, 21, 30, 39, 7, 28, 15, 49, 40, 42, 29], '实际特别号码': 25, '命中': '是'}\n",
            "{'期号': '2024355', '预测前 16 特别号码': [16, 32, 3, 46, 40, 9, 28, 21, 29, 15, 49, 30, 7, 25, 39, 42], '实际特别号码': 49, '命中': '是'}\n",
            "{'期号': '2024356', '预测前 16 特别号码': [16, 43, 3, 46, 32, 28, 9, 40, 7, 30, 15, 29, 25, 45, 14, 35], '实际特别号码': 46, '命中': '是'}\n",
            "{'期号': '2024357', '预测前 16 特别号码': [43, 46, 16, 3, 32, 14, 11, 30, 9, 45, 31, 25, 40, 48, 41, 28], '实际特别号码': 9, '命中': '是'}\n",
            "{'期号': '2024358', '预测前 16 特别号码': [43, 45, 48, 14, 46, 20, 11, 16, 3, 30, 31, 18, 28, 22, 41, 40], '实际特别号码': 21, '命中': '否'}\n",
            "{'期号': '2024359', '预测前 16 特别号码': [43, 45, 20, 22, 18, 46, 14, 42, 11, 30, 39, 29, 41, 16, 7, 31], '实际特别号码': 15, '命中': '否'}\n",
            "{'期号': '2024360', '预测前 16 特别号码': [45, 20, 43, 42, 18, 22, 14, 39, 46, 35, 41, 30, 36, 48, 8, 12], '实际特别号码': 14, '命中': '是'}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "预测下一期期号：2024361\n",
            "预测的前 16 个特别号码：[18 20 45 22 12 39 35  2 46 42 33 30 36 43  4  9]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, MultiHeadAttention, LayerNormalization, Input, Concatenate, GlobalAveragePooling1D, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 1. 从 API 获取数据\n",
        "def fetch_data_from_api(year):\n",
        "    url = f\"https://history.macaumarksix.com/history/macaujc2/y/{year}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if data['result']:\n",
        "            return data['data']\n",
        "        else:\n",
        "            print(f\"API 返回失败信息: {data['message']}\")\n",
        "            return []\n",
        "    else:\n",
        "        print(f\"请求失败，HTTP 状态码: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "# 2. 转换 API 数据为 DataFrame 格式并调整顺序\n",
        "def transform_api_data(api_data):\n",
        "    records = []\n",
        "    for item in api_data:\n",
        "        open_code = list(map(int, item['openCode'].split(',')))\n",
        "        records.append({\n",
        "            \"期号\": item[\"expect\"],\n",
        "            \"特别号码\": open_code[-1],\n",
        "            \"正码\": open_code[:-1],\n",
        "            \"开盘时间\": item[\"openTime\"],\n",
        "            \"波色\": item[\"wave\"].split(','),\n",
        "            \"生肖\": item[\"zodiac\"].split(',')\n",
        "        })\n",
        "    df = pd.DataFrame(records)\n",
        "    df = df.sort_values(by=\"期号\", ascending=True).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# 3. 数据增强\n",
        "def enhance_features(data):\n",
        "    data['特别号码尾数'] = data['特别号码'] % 10\n",
        "    data['红波数'] = data['波色'].apply(lambda x: x.count('red'))\n",
        "    data['蓝波数'] = data['波色'].apply(lambda x: x.count('blue'))\n",
        "    data['绿波数'] = data['波色'].apply(lambda x: x.count('green'))\n",
        "\n",
        "    # 冷热号特征\n",
        "    热号矩阵 = np.zeros((len(data), 49))\n",
        "    for i in range(1, 50):\n",
        "        recent_count = data['特别号码'].rolling(10).apply(lambda x: sum(x == i), raw=True).fillna(0)\n",
        "        热号矩阵[:, i - 1] = recent_count\n",
        "\n",
        "    热号_df = pd.DataFrame(热号矩阵, columns=[f'冷热号_{i}' for i in range(1, 50)])\n",
        "\n",
        "    # 区间特征\n",
        "    区间_df = pd.DataFrame({\n",
        "        '区间_1_10': data['特别号码'].apply(lambda x: 1 if 1 <= x <= 10 else 0),\n",
        "        '区间_11_20': data['特别号码'].apply(lambda x: 1 if 11 <= x <= 20 else 0),\n",
        "        '区间_21_30': data['特别号码'].apply(lambda x: 1 if 21 <= x <= 30 else 0),\n",
        "        '区间_31_40': data['特别号码'].apply(lambda x: 1 if 31 <= x <= 40 else 0),\n",
        "        '区间_41_49': data['特别号码'].apply(lambda x: 1 if 41 <= x <= 49 else 0),\n",
        "    })\n",
        "\n",
        "    # 贝叶斯特征\n",
        "    total_count = len(data)\n",
        "    for i in range(1, 50):\n",
        "        count_i = (data['特别号码'] == i).sum()\n",
        "        data[f'贝叶斯_{i}'] = (count_i / total_count) * (1 / 49)\n",
        "\n",
        "    # 合并特征\n",
        "    data = pd.concat([data.reset_index(drop=True), 热号_df, 区间_df], axis=1)\n",
        "    return data\n",
        "\n",
        "# 4. 准备数据\n",
        "def prepare_data(data, time_steps=10, validation_periods=100):\n",
        "    onehot_encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(data['特别号码'].values.reshape(-1, 1))\n",
        "\n",
        "    X, y, periods = [], [], []\n",
        "    for i in range(len(onehot_encoded) - time_steps):\n",
        "        X.append(onehot_encoded[i:i + time_steps])\n",
        "        y.append(onehot_encoded[i + time_steps])\n",
        "        periods.append(data.iloc[i + time_steps][\"期号\"])\n",
        "\n",
        "    X_train = X[:-validation_periods]\n",
        "    y_train = y[:-validation_periods]\n",
        "    X_val = X[-validation_periods:]\n",
        "    y_val = y[-validation_periods:]\n",
        "    periods_val = periods[-validation_periods:]\n",
        "\n",
        "    return np.array(X_train), np.array(y_train), np.array(X_val), np.array(y_val), periods_val\n",
        "\n",
        "# 5. 构建混合模型\n",
        "def build_model(input_shape):\n",
        "    lstm_input = Input(shape=input_shape)\n",
        "    lstm_output = LSTM(512, return_sequences=True, dropout=0.3)(lstm_input)\n",
        "    lstm_output = BatchNormalization()(lstm_output)\n",
        "    lstm_output = LSTM(256, return_sequences=False, dropout=0.3)(lstm_output)\n",
        "    lstm_output = BatchNormalization()(lstm_output)\n",
        "\n",
        "    transformer_output = MultiHeadAttention(num_heads=8, key_dim=128)(lstm_input, lstm_input)\n",
        "    transformer_output = GlobalAveragePooling1D()(transformer_output)\n",
        "\n",
        "    merged = Concatenate()([lstm_output, transformer_output])\n",
        "    final_output = Dense(49, activation='softmax', kernel_regularizer=l2(0.01))(merged)\n",
        "\n",
        "    model = Model(inputs=lstm_input, outputs=final_output)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# 6. 动态学习率\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.001\n",
        "    if epoch > 50:\n",
        "        lr *= 0.1\n",
        "    if epoch > 100:\n",
        "        lr *= 0.01\n",
        "    return lr\n",
        "\n",
        "# 7. 验证逻辑\n",
        "def calculate_accuracy(predicted, actual, periods, n=16):\n",
        "    correct = 0\n",
        "    results = []\n",
        "    for i in range(len(actual)):\n",
        "        top_n = np.argsort(predicted[i])[-n:][::-1] + 1\n",
        "        is_hit = actual[i] in top_n\n",
        "        if is_hit:\n",
        "            correct += 1\n",
        "        results.append({\n",
        "            \"期号\": periods[i],\n",
        "            \"预测前 16 特别号码\": list(top_n),\n",
        "            \"实际特别号码\": actual[i],\n",
        "            \"命中\": \"是\" if is_hit else \"否\"\n",
        "        })\n",
        "    accuracy = correct / len(actual)\n",
        "    return accuracy, results\n",
        "\n",
        "# 8. 下一期预测\n",
        "def predict_next_issue(model, data, time_steps=10):\n",
        "    onehot_encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(data['特别号码'].values.reshape(-1, 1))\n",
        "    latest_data = onehot_encoded[-time_steps:].reshape(1, time_steps, -1)\n",
        "    predicted = model.predict(latest_data)\n",
        "    top_16 = np.argsort(predicted[0])[-16:][::-1] + 1\n",
        "    last_issue = int(data.iloc[-1]['期号'])\n",
        "    next_issue = last_issue + 1\n",
        "    return next_issue, top_16\n",
        "\n",
        "# 9. 主程序\n",
        "if __name__ == \"__main__\":\n",
        "    year = 2024\n",
        "    api_data = fetch_data_from_api(year)\n",
        "    if not api_data:\n",
        "        print(\"未获取到有效数据，退出程序\")\n",
        "        exit()\n",
        "\n",
        "    data = transform_api_data(api_data)\n",
        "    data = enhance_features(data)\n",
        "\n",
        "    # 准备数据\n",
        "    time_steps = 10\n",
        "    validation_periods = 100\n",
        "    X_train, y_train, X_val, y_val, periods_val = prepare_data(data, time_steps, validation_periods)\n",
        "\n",
        "    # 构建模型\n",
        "    model = build_model(X_train.shape[1:])\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "    model.fit(X_train, y_train, epochs=360, batch_size=64, validation_split=0.2, callbacks=[lr_scheduler])\n",
        "\n",
        "    # 验证准确率\n",
        "    y_val_actual = np.argmax(y_val, axis=1) + 1\n",
        "    y_val_predicted = model.predict(X_val)\n",
        "    accuracy, results = calculate_accuracy(y_val_predicted, y_val_actual, periods_val, n=16)\n",
        "\n",
        "    print(f\"\\n验证集命中率：{accuracy * 100:.2f}%\")\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    # 下一期预测\n",
        "    next_issue, next_issue_prediction = predict_next_issue(model, data, time_steps)\n",
        "    print(f\"\\n预测下一期期号：{next_issue}\")\n",
        "    print(f\"预测的前 16 个特别号码：{next_issue_prediction}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4NzmUY5rvdrwGJ2T+36Qp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}